{"cells":[{"cell_type":"code","source":["# Creating gold schema\n","spark.sql(\"CREATE SCHEMA IF NOT EXISTS gold\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"253c8a07-2fe2-4849-8ed9-68ef6c370523"},{"cell_type":"code","source":["# Initial building of gold fact table\n","\n","from pyspark.sql.functions import  col, count, sum, when\n","\n","df_fact_base = spark.table(\"silver.appointments_clean\")\n","\n","df_practice = spark.table(\"gold.dim_practice\")\n","df_date = spark.table(\"gold.dim_date\")\n","\n","df_fact = (\n","    df_fact_base\n","    .groupBy(\"practice_code\", \"appointment_date\")\n","    .agg(\n","        count(\"*\").alias(\"total_appointments\"),\n","        sum(when(col(\"current_slot_status\") == \"DNA\", 1).otherwise(0)).alias(\"dna_count\"),\n","        sum(when(col(\"current_slot_status\") == \"Walked Out\", 1).otherwise(0)).alias(\"walked_out_count\"),\n","        sum(when(col(\"current_slot_status\") == \"Left\", 1).otherwise(0)).alias(\"completed_count\")\n","    )\n","    .withColumn(\"dna_rate\", col(\"dna_count\") / col(\"total_appointments\"))\n","    .withColumn(\"walked_out_rate\", col(\"walked_out_count\") / col(\"total_appointments\"))\n","    .join(df_practice, \"practice_code\")\n","    .join(df_date, \"appointment_date\")\n","    .select(\n","        \"practice_key\",\n","        \"practice_code\",\n","        \"date_key\",\n","        \"total_appointments\",\n","        \"dna_count\",\n","        \"walked_out_count\",\n","        \"completed_count\"\n","    )\n",")\n","\n","## Partitioning by date key\n","df_fact.write \\\n","    .partitionBy(\"date_key\") \\\n","    .saveAsTable(\"gold.fact_appointments\")\n","\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"cc958308-cc2c-48bb-8917-dda9ed5abf6e"},{"cell_type":"code","source":["\n","# Create metadata control table \n","spark.sql(\"\"\"\n","CREATE TABLE IF NOT EXISTS gold.pipeline_metadata (\n","    pipeline_name STRING,\n","    last_processed_date DATE\n",")\n","\"\"\")\n","\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"51dddf26-b42f-4b14-aee8-5a290cf584f2"},{"cell_type":"code","source":["# Insert inital values\n","spark.sql(\"\"\"\n","INSERT INTO gold.pipeline_metadata\n","VALUES ('fact_appointments_pipeline', '2025-01-01')\n","\"\"\")\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d8520362-6bc1-409f-b484-8a0d24edda75"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"c78f4bf2-9e3a-4dd5-9a5d-c57c7dce3503","known_lakehouses":[{"id":"c78f4bf2-9e3a-4dd5-9a5d-c57c7dce3503"}],"default_lakehouse_name":"portfolio_primary_care_lakehouse","default_lakehouse_workspace_id":"643f09ce-f571-48cd-b996-87de6f4d2ce9"}}},"nbformat":4,"nbformat_minor":5}